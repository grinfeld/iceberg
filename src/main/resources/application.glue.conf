app {
  # Override name for production environment
  name = "Avro to Iceberg Conversion - Production"
  master = "local[*]"
  master = ${?SPARK_MASTER_URL}
  create.table = true
  s3.from = "s3a://mikerusoft-parquet"

  config {
    spark {
      sql {
        catalog {
          mycatalog {
            def-impl = "org.apache.iceberg.spark.SparkCatalog"
            type = "glue"
            warehouse = "s3a://mikerusoft-test/warehouse"
            warehouse = ${?WAREHOUSE_PATH}
            glue.region = "us-east-1"
            glue.region = ${?WAREHOUSE_GLUE_REGION}
            io-impl: "org.apache.iceberg.aws.s3.S3FileIO"
          }
        }
      }

      hadoop {
        fs {
          s3a {
            access.key = "something"
            access.key = ${?AWS_ACCESS_KEY_ID}
            secret.key = "something"
            secret.key = ${?AWS_SECRET_ACCESS_KEY}
            impl = "org.apache.hadoop.fs.s3a.S3AFileSystem"
            // path.style.access = false
            // path.style.access = ${?S3_PATH_STYLE}
            // ssl.enabled = true
            // ssl.enabled = ${?S3_SSL_ENABLED}
            // aws.credentials.provider = "org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider"
          }
        }
      }
    }
  }
}