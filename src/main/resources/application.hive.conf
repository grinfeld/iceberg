app {
  # Override name for local environment
  name = "Avro to Iceberg Conversion - Local"
  master = "local[*]"
  create.table = true
  s3.from = "s3a://parquet"

  config {
    spark {
      sql {
        catalog {
          mycatalog {
            def-impl = "org.apache.iceberg.spark.SparkCatalog"
            type = "hive"
            uri = "thrift://localhost:9083"
            clients = 1
            warehouse = "s3a://test/warehouse"
            prefix = "test"
          }
        }
      }

      hadoop {
        fs {
          s3a {
            endpoint = "http://localhost:9000"
            endpoint = ${?STORAGE_ENDPOINT}
            access.key = "minioadmin"
            access.key = ${?STORAGE_KEY_ID}
            secret.key = "minioadmin"
            secret.key = ${?STORAGE_KEY_SECRET}
            path.style.access = true
            impl = "org.apache.hadoop.fs.s3a.S3AFileSystem"
            ssl.enabled = false
          }
        }
      }
    }
  }
}