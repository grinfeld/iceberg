app {
  # Override name for local environment
  name = "Avro to Iceberg Conversion - Local"
  master = "local[*]"
  create.table = true
  s3.from = "s3a://test/parquet"

  iceberg {
    database = "hive_catalog"
  }

  config {
    spark {
      sql {
        catalog {
          hive_catalog {
            def-impl = "org.apache.iceberg.spark.SparkCatalog"
            type = "hive"
//            catalog-impl = "org.apache.iceberg.hive.HiveCatalog"
            uri = "thrift://localhost:9083"
            clients = 1
            warehouse = "s3a://test/warehouse"
          }
        }
      }

      hadoop {
        fs {
          s3a {
            endpoint = "http://localhost:9000"
            access.key = "minioadmin"
            secret.key = "minioadmin"
            path.style.access = true
            impl = "org.apache.hadoop.fs.s3a.S3AFileSystem"
            ssl.enabled = false
//            aws.credentials.provider = "org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider"
          }
        }
      }
    }
  }
}